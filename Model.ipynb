{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9KKrciVsDkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "import time"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CCSRnCGsIIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('clean_data.csv')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw9dr_t-QojY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d752ae54-b716-4149-dd21-e577f5be7029"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3750, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO4O7TlJ-Nz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filtering out the required length of sentences \n",
        "seq_len = 30\n",
        "new_df = pd.DataFrame(columns = ['title', 'response'])\n",
        "for i in range(1, len(df.title)):\n",
        "    if len(df['title'][i].split()) <= seq_len and len(df['response'][i].split()) <= seq_len:\n",
        "        new_df = new_df.append({'title': df.title[i], 'response': df.response[i]}, ignore_index=True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQDOG5vuQthd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb919c5c-c5aa-4b80-f195-f068266c07b7"
      },
      "source": [
        "new_df.shape "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(920, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJVaVJHLcZkw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0fc28042-0c3d-4f07-8478-1bc066ab8865"
      },
      "source": [
        "new_df.tail()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>&lt;start&gt; came to terms with stress &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; where i can take this test online &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>&lt;start&gt; if this is any indication of how my li...</td>\n",
              "      <td>&lt;start&gt; i feel this on multiple levels . hang ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>&lt;start&gt; cod can help manage your stress &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; less cod oils helps me a lot dealing w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>&lt;start&gt; relative stress of confronting versus ...</td>\n",
              "      <td>&lt;start&gt; this sounds interesting , i would alwa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>&lt;start&gt; need to fulfill your promise &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; grandma i think you meant to send this...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 title                                           response\n",
              "915            <start> came to terms with stress <end>    <start> where i can take this test online <end>\n",
              "916  <start> if this is any indication of how my li...  <start> i feel this on multiple levels . hang ...\n",
              "917      <start> cod can help manage your stress <end>  <start> less cod oils helps me a lot dealing w...\n",
              "918  <start> relative stress of confronting versus ...  <start> this sounds interesting , i would alwa...\n",
              "919         <start> need to fulfill your promise <end>  <start> grandma i think you meant to send this..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi5sAlmusM32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating vocabulary funct\n",
        "def tokenize(text, lang):\n",
        "    tensor = lang.texts_to_sequences(list(text))   \n",
        "    tensor = pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6xy13MnPLxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating same vocab for both input and outputs/target\n",
        "inp = new_df.title.values.tolist()\n",
        "op = new_df.response.values.tolist()\n",
        "inp.extend(op)\n",
        "lang = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "lang.fit_on_texts(inp)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU3NdOfBsPT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = tokenize(new_df['title'], lang)\n",
        "target_tensor = tokenize(new_df['response'], lang)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYFu6QU7gskj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ce76ee4-c89a-4530-f42e-c822976cddb3"
      },
      "source": [
        "len(lang.word_counts) # vocab size - 1"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUC9eN_Qi5-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c1367cb-d593-48fd-a9c7-af2c9d54b652"
      },
      "source": [
        "len(input_tensor)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "920"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYbmxu7YaOVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_target, max_len_input = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYv09kqsshwj",
        "colab_type": "text"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dclvrpxcwWHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_size = len(lang.word_index)+1\n",
        "\n",
        "# creating dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor)).shuffle(BUFFER_SIZE)\n",
        "# combining consecutive elements of the dataset into batches\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1VPxLkf50pQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81f2418a-aa0d-46e2-ea85-57ba0bca3037"
      },
      "source": [
        "# example batches to check the functions\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 30]), TensorShape([64, 30]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWJ60iS4sgwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        # layers \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.enc_units), initializer=\"random_normal\", trainable=True)\n",
        "        self.b = self.add_weight(shape=(self.enc_units,), initializer=\"random_normal\", trainable=True)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))    "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpF6yXXyvGYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "4cc306ef-949e-40de-9d0e-b7e91f7868b0"
      },
      "source": [
        "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# testing the encoder layers on sample \n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
        "\n",
        "encoder.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 30, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n",
            "Model: \"encoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      multiple                  752384    \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  multiple                  3938304   \n",
            "=================================================================\n",
            "Total params: 4,722,432\n",
            "Trainable params: 4,722,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8gG866Zvtng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0NS837ux4qB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6d0e72dc-8e67-4c1a-e504-c2b312a98493"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "\n",
        "# testing the attention layer on thr sample data\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output) # give the encoder layer's output to the  attention model\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 30, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTQ9BqmIx9bR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.dec_units), initializer=\"random_normal\", trainable=True)\n",
        "        self.b = self.add_weight(shape=(self.dec_units,), initializer=\"random_normal\", trainable=True)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        output, state = self.gru(x)\n",
        "\n",
        "        output = tf.reshape(output, (-1, output.shape[2])) # (batch_size, hidden_size)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7AkmmFdyAsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "6ad061f8-7231-4441-d566-bd115b6e6b94"
      },
      "source": [
        "decoder = Decoder(vocab_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),sample_hidden, sample_output)\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n",
        "\n",
        "decoder.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 2939)\n",
            "Model: \"decoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      multiple                  752384    \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  multiple                  7084032   \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             multiple                  3012475   \n",
            "_________________________________________________________________\n",
            "bahdanau_attention_5 (Bahdan multiple                  2100225   \n",
            "=================================================================\n",
            "Total params: 12,951,164\n",
            "Trainable params: 12,951,164\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFgi3MidyDCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01F5xkEByHKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozVnwMl9r7iz",
        "colab_type": "text"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj2uHHGzwqkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnppBfnoyJcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        dec_input = tf.expand_dims([lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # print(targ.shape[1])\n",
        "        # using Teacher forcing\n",
        "        for t in range(1, targ.shape[1]):\n",
        "\n",
        "            # passing enc_output to the decoder\n",
        "            # decoder creates a context vector based on the input\n",
        "\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "            del predictions\n",
        "            gc.collect()\n",
        "\n",
        "    del dec_hidden\n",
        "    del dec_input\n",
        "    gc.collect()\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    del variables\n",
        "    del gradients\n",
        "    gc.collect()\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J9fj9akydSj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c7c7822-79ad-4948-dcb7-dbd3bb75607d"
      },
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "        \n",
        "    #   saving the model every 10 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.7373\n",
            "Epoch 1 Batch 10 Loss 1.6272\n",
            "Epoch 1 Loss 1.7040\n",
            "Time taken for 1 epoch 7.753515720367432 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.7368\n",
            "Epoch 2 Batch 10 Loss 1.6692\n",
            "Epoch 2 Loss 1.6434\n",
            "Time taken for 1 epoch 7.656006097793579 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.6193\n",
            "Epoch 3 Batch 10 Loss 1.6094\n",
            "Epoch 3 Loss 1.5911\n",
            "Time taken for 1 epoch 7.641568422317505 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.5565\n",
            "Epoch 4 Batch 10 Loss 1.5510\n",
            "Epoch 4 Loss 1.5421\n",
            "Time taken for 1 epoch 7.670429944992065 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.4945\n",
            "Epoch 5 Batch 10 Loss 1.8029\n",
            "Epoch 5 Loss 1.4991\n",
            "Time taken for 1 epoch 7.633963584899902 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.2832\n",
            "Epoch 6 Batch 10 Loss 1.5200\n",
            "Epoch 6 Loss 1.4522\n",
            "Time taken for 1 epoch 7.6587982177734375 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.4204\n",
            "Epoch 7 Batch 10 Loss 1.3455\n",
            "Epoch 7 Loss 1.3915\n",
            "Time taken for 1 epoch 7.647753477096558 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.4039\n",
            "Epoch 8 Batch 10 Loss 1.4676\n",
            "Epoch 8 Loss 1.3608\n",
            "Time taken for 1 epoch 7.657830238342285 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.2839\n",
            "Epoch 9 Batch 10 Loss 1.1831\n",
            "Epoch 9 Loss 1.3076\n",
            "Time taken for 1 epoch 7.611877679824829 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.2864\n",
            "Epoch 10 Batch 10 Loss 1.1799\n",
            "Epoch 10 Loss 1.2787\n",
            "Time taken for 1 epoch 7.6266608238220215 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 1.1019\n",
            "Epoch 11 Batch 10 Loss 1.3443\n",
            "Epoch 11 Loss 1.2439\n",
            "Time taken for 1 epoch 7.603137493133545 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 1.0490\n",
            "Epoch 12 Batch 10 Loss 1.2480\n",
            "Epoch 12 Loss 1.2030\n",
            "Time taken for 1 epoch 7.641332626342773 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 1.1321\n",
            "Epoch 13 Batch 10 Loss 1.1102\n",
            "Epoch 13 Loss 1.1530\n",
            "Time taken for 1 epoch 7.629086256027222 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 1.0692\n",
            "Epoch 14 Batch 10 Loss 1.2245\n",
            "Epoch 14 Loss 1.1141\n",
            "Time taken for 1 epoch 7.6292219161987305 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 1.0429\n",
            "Epoch 15 Batch 10 Loss 1.1827\n",
            "Epoch 15 Loss 1.0786\n",
            "Time taken for 1 epoch 7.612526178359985 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 1.0464\n",
            "Epoch 16 Batch 10 Loss 1.0211\n",
            "Epoch 16 Loss 1.0346\n",
            "Time taken for 1 epoch 7.61365818977356 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.9628\n",
            "Epoch 17 Batch 10 Loss 1.0475\n",
            "Epoch 17 Loss 0.9913\n",
            "Time taken for 1 epoch 7.6090004444122314 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.9754\n",
            "Epoch 18 Batch 10 Loss 0.8383\n",
            "Epoch 18 Loss 0.9559\n",
            "Time taken for 1 epoch 7.640519618988037 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.8954\n",
            "Epoch 19 Batch 10 Loss 0.9990\n",
            "Epoch 19 Loss 0.9101\n",
            "Time taken for 1 epoch 7.5883355140686035 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.8437\n",
            "Epoch 20 Batch 10 Loss 0.9260\n",
            "Epoch 20 Loss 0.8710\n",
            "Time taken for 1 epoch 7.612032651901245 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.8046\n",
            "Epoch 21 Batch 10 Loss 0.7845\n",
            "Epoch 21 Loss 0.8359\n",
            "Time taken for 1 epoch 7.624488115310669 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.7906\n",
            "Epoch 22 Batch 10 Loss 0.7743\n",
            "Epoch 22 Loss 0.7927\n",
            "Time taken for 1 epoch 7.624491930007935 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.7889\n",
            "Epoch 23 Batch 10 Loss 0.7287\n",
            "Epoch 23 Loss 0.7550\n",
            "Time taken for 1 epoch 7.57340407371521 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.6926\n",
            "Epoch 24 Batch 10 Loss 0.6896\n",
            "Epoch 24 Loss 0.7081\n",
            "Time taken for 1 epoch 7.605902910232544 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.7310\n",
            "Epoch 25 Batch 10 Loss 0.6623\n",
            "Epoch 25 Loss 0.6697\n",
            "Time taken for 1 epoch 7.584926128387451 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 0.5275\n",
            "Epoch 26 Batch 10 Loss 0.7861\n",
            "Epoch 26 Loss 0.6307\n",
            "Time taken for 1 epoch 7.617950201034546 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 0.4930\n",
            "Epoch 27 Batch 10 Loss 0.7254\n",
            "Epoch 27 Loss 0.5995\n",
            "Time taken for 1 epoch 7.595851898193359 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 0.3963\n",
            "Epoch 28 Batch 10 Loss 0.5887\n",
            "Epoch 28 Loss 0.5610\n",
            "Time taken for 1 epoch 7.5884175300598145 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.4544\n",
            "Epoch 29 Batch 10 Loss 0.4823\n",
            "Epoch 29 Loss 0.5238\n",
            "Time taken for 1 epoch 7.5998992919921875 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.3709\n",
            "Epoch 30 Batch 10 Loss 0.5054\n",
            "Epoch 30 Loss 0.4828\n",
            "Time taken for 1 epoch 7.605044603347778 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf3IsYAqGhmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the model\n",
        "encoder.save(\"my_model/encoder\")\n",
        "decoder.save(\"my_model/decoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA89NA3Wz29u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQCmuvJngiYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('./training_checkpoints')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhmgZFV3rydS",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPGea1u1OxLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkxhUgF8gMAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.strip()\n",
        "    w = w.lower()\n",
        "\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    # functions for spelling mistakes removals ans contractions are in other file...leave them be for now.\n",
        "\n",
        "    return w"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fis_Lpm_XZoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "\n",
        "    # modifying the input sentence to feed into the model\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = [lang.word_index[i] for i in sentence.split(' ') if i in lang.word_index.keys()] # conversion into tokens, skipping unknown words\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_len_input, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_len_target):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        # stopping the sentence prediction process as soon as end is predicted\n",
        "        if lang.index_word[predicted_id] == '<end>':\n",
        "            return result\n",
        "\n",
        "    # feeding the predicted Id back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfcBNzApZdoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bot_says(sentence):\n",
        "    result = evaluate(sentence)\n",
        "\n",
        "    # print('Input: %s' % (sentence))\n",
        "    print('Jolly : {}'.format(result))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CwTJaiqZYL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjXnZrpUZzwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bot_says('It makes me sad to go on like this without hope')\n",
        "bot_says('I do not know what to do')\n",
        "bot_says('I feel tired all the time')\n",
        "bot_says('I think no one likes me ')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p3RJ1l4Z6sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "greeting_words = ['hi', 'hello', 'wassup', 'good morning', 'good evening', 'good afternoon']\n",
        "# the chatting loop\n",
        "while True:\n",
        "    sentence = input('User : ')\n",
        "    if 'bye' in sentence.split(' '):\n",
        "        print('Jolly : Okay bye and take care.')\n",
        "        break\n",
        "    elif set(greeting_words) & set(sentence.split(' ')):\n",
        "        print('Jolly : Hello, I am a Jolly. I am here to help you. Please share your problem')\n",
        "    else:\n",
        "        bot_says(sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-7U8np2xYxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}